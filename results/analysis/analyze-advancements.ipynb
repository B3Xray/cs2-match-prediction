{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eec644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing deepseek-chat...\n",
      "Analyzing sabia3...\n",
      "Analyzing gpt41...\n",
      "Analyzing claude-sonnet-4...\n",
      "Analyzing claude-opus-4...\n",
      "Analyzing gpt-o4-mini...\n",
      "Analysis complete. Results saved in /Users/lui/oss/cs2-match-prediction/results/analysis/advancement-analysis.md\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "def parse_markdown_standings(content: str) -> Dict[str, Dict[str, List]]:\n",
    "    \"\"\"Parse markdown content and extract standings for each stage.\"\"\"\n",
    "    stages = {}\n",
    "    current_stage = None\n",
    "    \n",
    "    # Find stage sections and their tables\n",
    "    for line in content.split('\\n'):\n",
    "        if line.startswith('### '):\n",
    "            current_stage = line.replace('### ', '').strip()\n",
    "            stages[current_stage] = []\n",
    "        elif current_stage and '|' in line and not line.startswith('|---'):\n",
    "            if 'Team | W-L |' not in line:  # Skip header row\n",
    "                parts = [p.strip() for p in line.split('|')]\n",
    "                if len(parts) >= 3:\n",
    "                    team = parts[1].strip()\n",
    "                    wl = parts[2].strip()\n",
    "                    if wl.startswith('+'):\n",
    "                        wl = wl[1:]  # Remove the '+' prefix\n",
    "                    wins, losses = map(int, wl.split('-'))\n",
    "                    stages[current_stage].append({\n",
    "                        'team': team,\n",
    "                        'wins': wins,\n",
    "                        'losses': losses,\n",
    "                        'score': wins - losses\n",
    "                    })\n",
    "    \n",
    "    # Sort teams in each stage by wins-losses\n",
    "    for stage in stages:\n",
    "        stages[stage] = sorted(\n",
    "            stages[stage],\n",
    "            key=lambda x: (x['wins'], -x['losses']),\n",
    "            reverse=True\n",
    "        )\n",
    "    \n",
    "    return stages\n",
    "\n",
    "def get_advancing_teams(stage_data: List[dict], num_teams: int = 8) -> Set[str]:\n",
    "    \"\"\"Get the top N teams from a stage based on W-L record\"\"\"\n",
    "    sorted_teams = sorted(stage_data, key=lambda x: (x['wins'], -x['losses']), reverse=True)\n",
    "    return {team['team'] for team in sorted_teams[:num_teams]}\n",
    "\n",
    "def analyze_advancement_predictions():\n",
    "    # Setup paths\n",
    "    current_dir = Path.cwd()\n",
    "    if current_dir.name == 'analysis':\n",
    "        results_dir = current_dir.parent\n",
    "    else:\n",
    "        results_dir = current_dir\n",
    "    analysis_dir = results_dir / 'analysis'\n",
    "    analysis_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Read real world results\n",
    "    with open(results_dir / '0real-world' / 'README.md') as f:\n",
    "        real_world_content = f.read()\n",
    "    real_world_standings = parse_markdown_standings(real_world_content)\n",
    "    \n",
    "    # Get real world advancing teams for each stage\n",
    "    real_advancing = {\n",
    "        'stage1': get_advancing_teams(real_world_standings['stage1']),\n",
    "        'stage2': get_advancing_teams(real_world_standings['stage2']),\n",
    "        'stage3': get_advancing_teams(real_world_standings['stage3'])\n",
    "    }\n",
    "    \n",
    "    # Get real world champion\n",
    "    playoffs_data = real_world_standings['playoffs']\n",
    "    real_champion = next(team['team'] for team in playoffs_data if team['wins'] == 3)\n",
    "    \n",
    "    # Analyze each model\n",
    "    results = {}\n",
    "    for model_dir in results_dir.iterdir():\n",
    "        if model_dir.is_dir() and model_dir.name != '0real-world' and not model_dir.name.startswith('.'):\n",
    "            model_path = model_dir / 'README.md'\n",
    "            if model_path.exists():\n",
    "                print(f\"Analyzing {model_dir.name}...\")\n",
    "                \n",
    "                # Read model predictions\n",
    "                with open(model_path) as f:\n",
    "                    model_content = f.read()\n",
    "                model_standings = parse_markdown_standings(model_content)\n",
    "                \n",
    "                # Analyze each stage\n",
    "                model_results = {\n",
    "                    'stage1': {'correct': 0, 'teams': set()},\n",
    "                    'stage2': {'correct': 0, 'teams': set()},\n",
    "                    'stage3': {'correct': 0, 'teams': set()},\n",
    "                    'champion': {'correct': False, 'predicted': ''}\n",
    "                }\n",
    "                \n",
    "                # Check advancing teams predictions\n",
    "                for stage in ['stage1', 'stage2', 'stage3']:\n",
    "                    predicted_teams = get_advancing_teams(model_standings[stage])\n",
    "                    correct_teams = predicted_teams & real_advancing[stage]\n",
    "                    model_results[stage]['correct'] = len(correct_teams)\n",
    "                    model_results[stage]['teams'] = predicted_teams\n",
    "                \n",
    "                # Check champion prediction\n",
    "                playoffs_data = model_standings['playoffs']\n",
    "                predicted_champion = next(team['team'] for team in playoffs_data if team['wins'] == 3)\n",
    "                model_results['champion']['correct'] = (predicted_champion == real_champion)\n",
    "                model_results['champion']['predicted'] = predicted_champion\n",
    "                \n",
    "                results[model_dir.name] = model_results\n",
    "    \n",
    "    # Generate report\n",
    "    report = [\"# CS2 Match Prediction Advancement Analysis\\n\\n\"]\n",
    "    \n",
    "    # Summary table\n",
    "    report.append(\"## Summary\\n\\n\")\n",
    "    report.append(\"| Model | Stage 1 | Stage 2 | Stage 3 | Champion Prediction |\\n\")\n",
    "    report.append(\"|-------|----------|----------|----------|--------------------|\")\n",
    "    \n",
    "    for model, data in results.items():\n",
    "        stage1_pct = (data['stage1']['correct'] / 8) * 100\n",
    "        stage2_pct = (data['stage2']['correct'] / 8) * 100\n",
    "        stage3_pct = (data['stage3']['correct'] / 8) * 100\n",
    "        champion = \"✓\" if data['champion']['correct'] else f\"✗ ({data['champion']['predicted']})\"\n",
    "        \n",
    "        report.append(f\"| {model} | {stage1_pct:.1f}% | {stage2_pct:.1f}% | {stage3_pct:.1f}% | {champion} |\")\n",
    "    \n",
    "    report.append(\"\\n\\n## Detailed Analysis\\n\")\n",
    "    \n",
    "    # Detailed analysis for each model\n",
    "    for model, data in results.items():\n",
    "        report.append(f\"\\n### {model}\\n\")\n",
    "        \n",
    "        for stage in ['stage1', 'stage2', 'stage3']:\n",
    "            correct = data[stage]['correct']\n",
    "            predicted = data[stage]['teams']\n",
    "            actual = real_advancing[stage]\n",
    "            \n",
    "            report.append(f\"\\n#### {stage}\")\n",
    "            report.append(f\"- Correctly predicted {correct}/8 teams ({(correct/8)*100:.1f}%)\")\n",
    "            report.append(\"- Missed predictions:\")\n",
    "            report.append(\"  - Should have advanced: \" + \", \".join(sorted(actual - predicted)))\n",
    "            report.append(\"  - Should not have advanced: \" + \", \".join(sorted(predicted - actual)))\n",
    "        \n",
    "        report.append(f\"\\n#### Playoffs\")\n",
    "        report.append(f\"- Predicted champion: {data['champion']['predicted']}\")\n",
    "        report.append(f\"- Actual champion: {real_champion}\")\n",
    "        report.append(f\"- Prediction {'correct' if data['champion']['correct'] else 'incorrect'}\")\n",
    "        \n",
    "        report.append(\"\\n---\\n\")\n",
    "    \n",
    "    # Save report\n",
    "    with open(analysis_dir / 'advancement-analysis.md', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved in {analysis_dir}/analyze-advancements.md\")\n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "advancement_results = analyze_advancement_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56458b1",
   "metadata": {},
   "source": [
    "# Data Viz\n",
    "\n",
    "which charts can we show based on the above analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a1895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def create_visualizations(results: Dict, analysis_dir: Path):\n",
    "    # Convert results to DataFrame for easier plotting\n",
    "    stage_data = []\n",
    "    for model, data in results.items():\n",
    "        for stage in ['stage1', 'stage2', 'stage3']:\n",
    "            stage_data.append({\n",
    "                'Model': model,\n",
    "                'Stage': stage.replace('stage', 'Stage '),\n",
    "                'Accuracy': (data[stage]['correct'] / 8) * 100\n",
    "            })\n",
    "    df = pd.DataFrame(stage_data)\n",
    "\n",
    "    # 1. Heatmap with original color scaling\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    accuracy_matrix = df.pivot(index='Model', columns='Stage', values='Accuracy')\n",
    "    \n",
    "    sns.heatmap(accuracy_matrix, \n",
    "                annot=True, \n",
    "                fmt='.1f',\n",
    "                cmap='RdYlGn',\n",
    "                center=50)\n",
    "    \n",
    "    # Add % to annotations\n",
    "    for t in plt.gca().texts:\n",
    "        t.set_text(t.get_text() + '%')\n",
    "    \n",
    "    plt.title('Team Advancement Prediction Accuracy by Model and Stage', pad=20, size=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(analysis_dir / 'accuracy_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Bar plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    overall_accuracy = df.groupby('Model')['Accuracy'].mean().sort_values(ascending=False)\n",
    "    ax = overall_accuracy.plot(kind='bar', color=sns.color_palette('viridis', len(overall_accuracy)))\n",
    "    plt.title('Average Prediction Accuracy Across All Stages', pad=20, size=14)\n",
    "    plt.ylabel('Average Accuracy (%)')\n",
    "    plt.xlabel('Model')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(overall_accuracy):\n",
    "        ax.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(analysis_dir / 'overall_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def add_visualization_section(report: List[str]):\n",
    "    report.append(\"\\n## Visualizations\\n\\n\")\n",
    "    report.append(\"### Accuracy Heatmap\\n\")\n",
    "    report.append(\"The heatmap below shows the accuracy percentage for each model across different stages. \"+\n",
    "                 \"Green indicates higher accuracy, while red indicates lower accuracy.\\n\\n\")\n",
    "    report.append(\"![Accuracy Heatmap](accuracy_heatmap.png)\\n\\n\")\n",
    "    report.append(\"### Overall Model Performance\\n\")\n",
    "    report.append(\"Average prediction accuracy across all stages for each model:\\n\\n\")\n",
    "    report.append(\"![Overall Performance](overall_performance.png)\\n\\n\")\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'analysis':\n",
    "    results_dir = current_dir.parent\n",
    "else:\n",
    "    results_dir = current_dir\n",
    "analysis_dir = results_dir / 'analysis'\n",
    "analysis_dir.mkdir(exist_ok=True)\n",
    "create_visualizations(advancement_results, analysis_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
