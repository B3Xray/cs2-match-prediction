{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c251473",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "\n",
    "teams = [\n",
    "    \"Complexity\", \"OG\", \"HEROIC\", \"Chinggis Warriors\", \"B8\", \"Imperial\",\n",
    "    \"BetBoom\", \"Nemiga\", \"TYLOO\", \"NRG\", \"Lynn Vision\", \"Legacy\",\n",
    "    \"Wildcard\", \"Metizport\", \"FlyQuest\", \"Fluxo\", \"Falcons\", \"FAZE\",\n",
    "    \"3DMAX\", \"Virtus.pro\", \"FURIA\", \"MIBR\", \"paiN\", \"M80\",\n",
    "    \"Aurora\", \"G2\", \"Natus Vincere\", \"Liquid\", \"Vitality\", \"MOUZ\",\n",
    "    \"Spirit\", \"The MongolZ\"\n",
    "]\n",
    "\n",
    "stages = ['stage1', 'stage2', 'stage3', 'playoffs']\n",
    "\n",
    "def list_model_directories():\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Current directory: {current_dir}\")\n",
    "    \n",
    "    # List all items in the current directory\n",
    "    model_dirs = [d for d in os.listdir() if os.path.isdir(d) and not d.startswith('stats')]\n",
    "    print(f\"Found model directories: {model_dirs}\")\n",
    "    return model_dirs\n",
    "\n",
    "def get_team_stats(model: str, team: str, stage: str) -> Optional[dict]:\n",
    "    try:\n",
    "        file_path = f\"{model}/{stage}/championship-cached/{team}.json\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return None\n",
    "\n",
    "def subtract_previous_results(current: dict, previous: dict) -> dict:\n",
    "    if not previous:\n",
    "        return current\n",
    "    \n",
    "    # Deep copy to avoid modifying original\n",
    "    result = current.copy()\n",
    "    \n",
    "    # Subtract wins and losses\n",
    "    result['wins'] = current['wins'] - previous['wins']\n",
    "    result['losses'] = current['losses'] - previous['losses']\n",
    "    \n",
    "    # Handle wins_against with duplicates\n",
    "    current_wins = current['win over'].split(',')\n",
    "    current_wins = [x.strip() for x in current_wins if x.strip()]\n",
    "    previous_wins = previous['win over'].split(',')\n",
    "    previous_wins = [x.strip() for x in previous_wins if x.strip()]\n",
    "    \n",
    "    # Convert to lists to maintain duplicates\n",
    "    new_wins = []\n",
    "    prev_wins_count = {}\n",
    "    for team in previous_wins:\n",
    "        prev_wins_count[team] = prev_wins_count.get(team, 0) + 1\n",
    "        \n",
    "    for team in current_wins:\n",
    "        if team in prev_wins_count and prev_wins_count[team] > 0:\n",
    "            prev_wins_count[team] -= 1\n",
    "        else:\n",
    "            new_wins.append(team)\n",
    "            \n",
    "    result['win over'] = ', '.join(new_wins)\n",
    "    \n",
    "    # Handle losses_against with duplicates\n",
    "    current_losses = current['loss over'].split(',')\n",
    "    current_losses = [x.strip() for x in current_losses if x.strip()]\n",
    "    previous_losses = previous['loss over'].split(',')\n",
    "    previous_losses = [x.strip() for x in previous_losses if x.strip()]\n",
    "    \n",
    "    # Convert to lists to maintain duplicates\n",
    "    new_losses = []\n",
    "    prev_losses_count = {}\n",
    "    for team in previous_losses:\n",
    "        prev_losses_count[team] = prev_losses_count.get(team, 0) + 1\n",
    "        \n",
    "    for team in current_losses:\n",
    "        if team in prev_losses_count and prev_losses_count[team] > 0:\n",
    "            prev_losses_count[team] -= 1\n",
    "        else:\n",
    "            new_losses.append(team)\n",
    "            \n",
    "    result['loss over'] = ', '.join(new_losses)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def generate_markdown_report(stage_stats: Dict[str, dict], stage: str) -> str:\n",
    "    markdown = f\"### {stage}\\n\\n\"\n",
    "    \n",
    "    if stage_stats:\n",
    "        markdown += \"| Team | W-L | New Wins Against | New Losses Against |\\n\"\n",
    "        markdown += \"|------|-----|-----------------|------------------|\\n\"\n",
    "        \n",
    "        # Sort teams by wins and losses\n",
    "        sorted_teams = sorted(\n",
    "            stage_stats.items(),\n",
    "            key=lambda x: (x[1]['wins'], -x[1]['losses']),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for team, stats in sorted_teams:\n",
    "            # Only add '+' if there are new wins or losses\n",
    "            prefix = \"+\" if (stats['win over'] or stats['loss over']) else \"\"\n",
    "            markdown += f\"| {team} | {prefix}{stats['wins']}-{stats['losses']} | \"\n",
    "            markdown += f\"{stats['win over'] or '-'} | {stats['loss over'] or '-'} |\\n\"\n",
    "    else:\n",
    "        markdown += \"*No new results for this stage*\\n\"\n",
    "    \n",
    "    markdown += \"\\n\"\n",
    "    return markdown\n",
    "\n",
    "# Collect all data first\n",
    "models_data = {}\n",
    "\n",
    "for model in list_model_directories():\n",
    "    models_data[model] = {}\n",
    "    previous_stage_data = {}\n",
    "    \n",
    "    for stage in stages:\n",
    "        stage_stats = {}\n",
    "        \n",
    "        for team in teams:\n",
    "            current_data = get_team_stats(model, team, stage)\n",
    "            if current_data:\n",
    "                prev_data = previous_stage_data.get(team)\n",
    "                \n",
    "                if prev_data:\n",
    "                    incremental_data = subtract_previous_results(current_data, prev_data)\n",
    "                else:\n",
    "                    incremental_data = current_data\n",
    "                \n",
    "                if incremental_data['wins'] > 0 or incremental_data['losses'] > 0:\n",
    "                    stage_stats[team] = incremental_data\n",
    "                \n",
    "                previous_stage_data[team] = current_data\n",
    "        \n",
    "        if stage_stats:\n",
    "            models_data[model][stage] = stage_stats\n",
    "\n",
    "# Generate and save individual README files for each model\n",
    "for model, stages_data in models_data.items():\n",
    "    markdown_content = f\"# {model} Results\\n\\n\"\n",
    "    \n",
    "    for stage in stages:\n",
    "        stage_stats = stages_data.get(stage, {})\n",
    "        markdown_content += generate_markdown_report(stage_stats, stage)\n",
    "    \n",
    "    # Save to model-specific README\n",
    "    readme_path = os.path.join(model, 'README.md')\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(markdown_content)\n",
    "    \n",
    "    print(f\"Created README.md for {model}\")\n",
    "\n",
    "# Generate main README.md with all models' results\n",
    "main_markdown = \"# CS2 Match Prediction Results\\n\\n\"\n",
    "\n",
    "for model, stages_data in models_data.items():\n",
    "    main_markdown += f\"## {model}\\n\\n\"\n",
    "    \n",
    "    for stage in stages:\n",
    "        stage_stats = stages_data.get(stage, {})\n",
    "        main_markdown += generate_markdown_report(stage_stats, stage)\n",
    "    \n",
    "    main_markdown += \"---\\n\\n\"\n",
    "\n",
    "# Save main README.md\n",
    "analysis_path = os.path.join('analysis', 'analysis-raw.md')\n",
    "with open(analysis_path, 'w') as f:\n",
    "    f.write(main_markdown)\n",
    "\n",
    "print(\"Created main analysis file with all results\")\n",
    "print(\"\\nAll README files have been created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
